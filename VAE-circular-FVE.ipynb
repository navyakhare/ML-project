{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import simtk.openmm as mm\n",
    "from msmbuilder.decomposition import tICA, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFull = np.loadtxt('ala4_explicit/COLVAR_md_explicit_10ns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataFull[:,1:7]\n",
    "sumabs=dataFull[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.401463  2.721934 -1.359381  2.476104 -1.271216  2.361919]\n",
      " [-2.341986  2.873031 -1.109471  2.587082 -1.49281  -3.125739]\n",
      " [-2.458682  2.601563 -1.365601  2.60777  -1.5563    3.084817]\n",
      " ...\n",
      " [-1.381258  2.279866 -2.30461   3.077384 -1.124621  2.815719]\n",
      " [-1.695112  1.912944 -1.793466  2.932431 -1.201032  2.709006]\n",
      " [-1.37564   1.898676 -1.830701  2.715888 -0.99448   2.054822]]\n",
      "[0.758897 0.759956 0.749528 ... 0.463711 0.542259 0.610034]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(sumabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sincos=[]\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    temp=[]\n",
    "    for j in range(0,6):\n",
    "        temp.append(np.sin(data[i,j]))\n",
    "        temp.append(np.cos(data[i,j]))\n",
    "    sincos.append(temp)\n",
    "\n",
    "diheds_sincos=np.array(sincos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.397509  1.983793  1.776999  ... 1.375204  0.9172205 1.062112 ]\n"
     ]
    }
   ],
   "source": [
    "fe = np.loadtxt('ala4_explicit/fe')\n",
    "print(fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.67438365 -0.73838113  0.40744875 -0.91322807 -0.9777349   0.20984392\n",
      "  0.61744359 -0.78661516 -0.95546043  0.29511925  0.70304738 -0.71114301]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-41869.03006544425"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sumabs\n",
    "X_dihed = diheds_sincos\n",
    "y = fe\n",
    "\n",
    "xnew_sincos=[]\n",
    "xnew=[]\n",
    "ynew=[]\n",
    "for i in range(0,len(X)):\n",
    "    t1=[]\n",
    "    t1.append(X[i])\n",
    "    xnew.append(t1)\n",
    "    t2=[]\n",
    "    #t2.append(y[i])\n",
    "    #ynew.append(t2)\n",
    "    t3=[]\n",
    "    for j in range(0,12):\n",
    "        t3.append(X_dihed[i][j])\n",
    "    xnew_sincos.append(t3)\n",
    "\n",
    "xnew=np.array(xnew)\n",
    "#ynew=np.array(ynew)\n",
    "xnew_sincos=np.array(xnew_sincos)\n",
    "\n",
    "print(xnew_sincos[0])\n",
    "sum(xnew_sincos[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8373638540318044\n",
      "-0.11089574722092439\n",
      "0.3988736246362931\n",
      "-0.6151028330760221\n",
      "-0.8623292715556716\n",
      "-0.05009631871410182\n",
      "0.22080465483150075\n",
      "-0.28863031532459527\n",
      "-0.8339834437230369\n",
      "-0.1470649727591676\n",
      "0.33971750888719676\n",
      "-0.49980440773681223\n",
      "[ 0.1629802  -0.62748538  0.00857513 -0.29812524 -0.11540562  0.25994024\n",
      "  0.39663893 -0.49798485 -0.12147698  0.44218422  0.36332987 -0.21133861]\n"
     ]
    }
   ],
   "source": [
    "x_sincos_centered=xnew_sincos\n",
    "\n",
    "for i in range(0,len(xnew_sincos[0])):\n",
    "    avg=sum(xnew_sincos[:,i])/len(xnew_sincos)\n",
    "    print(avg)\n",
    "    x_sincos_centered[:,i]=x_sincos_centered[:,i]-avg\n",
    "    \n",
    "print(x_sincos_centered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 12) (40000,) (10001,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_sincos_centered, sumabs, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape, y_train.shape,y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "from keras.layers import Lambda, Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular(args):\n",
    "    \n",
    "    z_circular = args\n",
    "    #print(z_circular)\n",
    "    #print(K.sum(K.square(z_circular),axis=-1,keepdims=True))\n",
    "    return z_circular/K.sqrt(K.sum(K.square(z_circular),axis=-1,keepdims=True))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 50        \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 362\n",
      "Trainable params: 362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           312         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            50          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            50          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4)            0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 412\n",
      "Trainable params: 412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 24)                72        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 12)                300       \n",
      "=================================================================\n",
      "Total params: 372\n",
      "Trainable params: 372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 12)                300       \n",
      "=================================================================\n",
      "Total params: 420\n",
      "Trainable params: 420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 24)                168       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 12)                300       \n",
      "=================================================================\n",
      "Total params: 468\n",
      "Trainable params: 468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 24)                216       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                300       \n",
      "=================================================================\n",
      "Total params: 516\n",
      "Trainable params: 516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 24)                264       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 12)                300       \n",
      "=================================================================\n",
      "Total params: 564\n",
      "Trainable params: 564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_dim=12\n",
    "inputs = Input(shape=(original_dim,),name='encoder_input')\n",
    "latent_dim = 2\n",
    "batch_size=100\n",
    "epochs=500\n",
    "\n",
    "    \n",
    "x = Dense(24)(inputs)\n",
    "#x = Dense(8, activation='tanh')(x)\n",
    " \n",
    "z1 = Dense(latent_dim,activation='tanh')(x)\n",
    "z2 = Dense(latent_dim,activation='tanh')(x)\n",
    "z3 = Dense(latent_dim,activation='tanh')(x)\n",
    "z4 = Dense(latent_dim,activation='tanh')(x)\n",
    "z5 = Dense(latent_dim,activation='tanh')(x)\n",
    "\n",
    "z_circular1 = Lambda(circular, output_shape=(latent_dim,))(z1)\n",
    "z_circular2 = Lambda(circular, output_shape=(latent_dim,))(z2)\n",
    "z_circular3 = Lambda(circular, output_shape=(latent_dim,))(z3)\n",
    "z_circular4 = Lambda(circular, output_shape=(latent_dim,))(z4)\n",
    "z_circular5 = Lambda(circular, output_shape=(latent_dim,))(z5)\n",
    "\n",
    "z_conc = Concatenate()([z_circular1,z_circular2,z_circular3,z_circular4,z_circular5])\n",
    "\n",
    "encoder1 = Model(inputs,  z_circular1)\n",
    "encoder1.summary()\n",
    "\n",
    "encoder2 = Model(inputs,  Concatenate()([z_circular1,z_circular2]))\n",
    "encoder2.summary()\n",
    "\n",
    "encoder3 = Model(inputs,  Concatenate()([z_circular1,z_circular2,z_circular3]))\n",
    "encoder4 = Model(inputs,  Concatenate()([z_circular1,z_circular2,z_circular3,z_circular4]))\n",
    "encoder5 = Model(inputs,  Concatenate()([z_circular1,z_circular2,z_circular3,z_circular4,z_circular5]))\n",
    "\n",
    "latent_inputs1 = Input(shape=(2,))\n",
    "latent_inputs2 = Input(shape=(4,))\n",
    "latent_inputs3 = Input(shape=(6,))\n",
    "latent_inputs4 = Input(shape=(8,))\n",
    "latent_inputs5 = Input(shape=(10,))\n",
    "\n",
    "x = Dense(24, activation='tanh')(latent_inputs1)\n",
    "outputs1 = Dense(original_dim, activation='tanh')(x)\n",
    "decoder1 = Model(latent_inputs1, outputs1, name='decoder')\n",
    "decoder1.summary()\n",
    "outputs1 = decoder1(encoder1(inputs))\n",
    "vae1 = Model(inputs, outputs1, name='vae_mlp1')\n",
    "\n",
    "x = Dense(24, activation='tanh')(latent_inputs2)\n",
    "outputs2 = Dense(original_dim, activation='tanh')(x)\n",
    "decoder2 = Model(latent_inputs2, outputs2, name='decoder')\n",
    "decoder2.summary()\n",
    "outputs2 = decoder2(encoder2(inputs))\n",
    "vae2 = Model(inputs, outputs2, name='vae_mlp2')\n",
    "\n",
    "x = Dense(24, activation='tanh')(latent_inputs3)\n",
    "outputs3 = Dense(original_dim, activation='tanh')(x)\n",
    "decoder3 = Model(latent_inputs3, outputs3, name='decoder')\n",
    "decoder3.summary()\n",
    "outputs3 = decoder3(encoder3(inputs))\n",
    "vae3 = Model(inputs, outputs3, name='vae_mlp3')\n",
    "\n",
    "x = Dense(24, activation='tanh')(latent_inputs4)\n",
    "outputs4 = Dense(original_dim, activation='tanh')(x)\n",
    "decoder4 = Model(latent_inputs4, outputs4, name='decoder')\n",
    "decoder4.summary()\n",
    "outputs4 = decoder4(encoder4(inputs))\n",
    "vae4 = Model(inputs, outputs4, name='vae_mlp4')\n",
    "\n",
    "x = Dense(24, activation='tanh')(latent_inputs5)\n",
    "outputs5 = Dense(original_dim, activation='tanh')(x)\n",
    "decoder5 = Model(latent_inputs5, outputs5, name='decoder')\n",
    "decoder5.summary()\n",
    "outputs5 = decoder5(encoder5(inputs))\n",
    "vae5 = Model(inputs, outputs5, name='vae_mlp5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_mlp1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 2)                 362       \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 12)                372       \n",
      "=================================================================\n",
      "Total params: 734\n",
      "Trainable params: 734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"vae_mlp2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 4)                 412       \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 12)                420       \n",
      "=================================================================\n",
      "Total params: 832\n",
      "Trainable params: 832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"vae_mlp3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 6)                 462       \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 12)                468       \n",
      "=================================================================\n",
      "Total params: 930\n",
      "Trainable params: 930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"vae_mlp4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 8)                 512       \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 12)                516       \n",
      "=================================================================\n",
      "Total params: 1,028\n",
      "Trainable params: 1,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"vae_mlp5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "model_5 (Model)              (None, 10)                562       \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 12)                564       \n",
      "=================================================================\n",
      "Total params: 1,126\n",
      "Trainable params: 1,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navya/anaconda3/envs/msm_env/lib/python2.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "reconstruction_loss1 = mse(inputs, outputs1)\n",
    "reconstruction_loss1 *= original_dim\n",
    "vae1.add_loss(reconstruction_loss1)\n",
    "vae1.compile(optimizer='rmsprop')\n",
    "vae1.summary()\n",
    "\n",
    "reconstruction_loss2 = mse(inputs, outputs2)\n",
    "reconstruction_loss2 *= original_dim\n",
    "vae2.add_loss(reconstruction_loss2)\n",
    "vae2.compile(optimizer='rmsprop')\n",
    "vae2.summary()\n",
    "\n",
    "reconstruction_loss3 = mse(inputs, outputs3)\n",
    "reconstruction_loss3 *= original_dim\n",
    "vae3.add_loss(reconstruction_loss3)\n",
    "vae3.compile(optimizer='rmsprop')\n",
    "vae3.summary()\n",
    "\n",
    "reconstruction_loss4 = mse(inputs, outputs4)\n",
    "reconstruction_loss4 *= original_dim\n",
    "vae4.add_loss(reconstruction_loss4)\n",
    "vae4.compile(optimizer='rmsprop')\n",
    "vae4.summary()\n",
    "\n",
    "reconstruction_loss5 = mse(inputs, outputs5)\n",
    "reconstruction_loss5 *= original_dim\n",
    "vae5.add_loss(reconstruction_loss5)\n",
    "vae5.compile(optimizer='rmsprop')\n",
    "vae5.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10001 samples\n",
      "Epoch 1/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.6895 - val_loss: 1.4986\n",
      "Epoch 2/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.4697 - val_loss: 1.4555\n",
      "Epoch 3/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.4255 - val_loss: 1.4175\n",
      "Epoch 4/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.3883 - val_loss: 1.3752\n",
      "Epoch 5/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.3375 - val_loss: 1.3212\n",
      "Epoch 6/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.2992 - val_loss: 1.2979\n",
      "Epoch 7/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.2798 - val_loss: 1.2793\n",
      "Epoch 8/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.2657 - val_loss: 1.2695\n",
      "Epoch 9/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.2574 - val_loss: 1.2621\n",
      "Epoch 10/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.2525 - val_loss: 1.2574\n",
      "Epoch 11/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.2490 - val_loss: 1.2544\n",
      "Epoch 12/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.2456 - val_loss: 1.2619\n",
      "Epoch 13/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.2422 - val_loss: 1.2478\n",
      "Epoch 14/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.2393 - val_loss: 1.2454\n",
      "Epoch 15/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.2367 - val_loss: 1.2416\n",
      "Epoch 16/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.2332 - val_loss: 1.2426\n",
      "Epoch 17/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.2301 - val_loss: 1.2337\n",
      "Epoch 18/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.2254 - val_loss: 1.2289\n",
      "Epoch 19/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.2193 - val_loss: 1.2216\n",
      "Epoch 20/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.2092 - val_loss: 1.2099\n",
      "Epoch 21/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.2010 - val_loss: 1.2052\n",
      "Epoch 22/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.1965 - val_loss: 1.1985\n",
      "Epoch 23/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1929 - val_loss: 1.1960\n",
      "Epoch 24/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.1887 - val_loss: 1.1951\n",
      "Epoch 25/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1860 - val_loss: 1.1909\n",
      "Epoch 26/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1834 - val_loss: 1.1976\n",
      "Epoch 27/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.1811 - val_loss: 1.1884\n",
      "Epoch 28/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.1783 - val_loss: 1.1845\n",
      "Epoch 29/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1767 - val_loss: 1.1841\n",
      "Epoch 30/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.1742 - val_loss: 1.1816\n",
      "Epoch 31/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.1719 - val_loss: 1.1782\n",
      "Epoch 32/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.1695 - val_loss: 1.1799\n",
      "Epoch 33/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.1671 - val_loss: 1.1746\n",
      "Epoch 34/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.1639 - val_loss: 1.1706\n",
      "Epoch 35/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1600 - val_loss: 1.1656\n",
      "Epoch 36/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.1542 - val_loss: 1.1608\n",
      "Epoch 37/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.1476 - val_loss: 1.1512\n",
      "Epoch 38/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1391 - val_loss: 1.1445\n",
      "Epoch 39/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.1316 - val_loss: 1.1369\n",
      "Epoch 40/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1224 - val_loss: 1.1311\n",
      "Epoch 41/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.1132 - val_loss: 1.1212\n",
      "Epoch 42/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1072 - val_loss: 1.1197\n",
      "Epoch 43/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.1010 - val_loss: 1.1080\n",
      "Epoch 44/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0966 - val_loss: 1.1046\n",
      "Epoch 45/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0928 - val_loss: 1.1045\n",
      "Epoch 46/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0894 - val_loss: 1.1007\n",
      "Epoch 47/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0872 - val_loss: 1.0989\n",
      "Epoch 48/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0851 - val_loss: 1.0971\n",
      "Epoch 49/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0829 - val_loss: 1.0953\n",
      "Epoch 50/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0811 - val_loss: 1.0936\n",
      "Epoch 51/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0796 - val_loss: 1.0913\n",
      "Epoch 52/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0788 - val_loss: 1.0967\n",
      "Epoch 53/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0772 - val_loss: 1.0876\n",
      "Epoch 54/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0760 - val_loss: 1.0858\n",
      "Epoch 55/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0747 - val_loss: 1.0856\n",
      "Epoch 56/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0731 - val_loss: 1.0846\n",
      "Epoch 57/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0724 - val_loss: 1.0837\n",
      "Epoch 58/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0709 - val_loss: 1.0824\n",
      "Epoch 59/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0700 - val_loss: 1.0813\n",
      "Epoch 60/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0682 - val_loss: 1.0794\n",
      "Epoch 61/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0669 - val_loss: 1.0806\n",
      "Epoch 62/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0654 - val_loss: 1.0770\n",
      "Epoch 63/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.0638 - val_loss: 1.0768\n",
      "Epoch 64/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0625 - val_loss: 1.0739\n",
      "Epoch 65/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0608 - val_loss: 1.0717\n",
      "Epoch 66/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0595 - val_loss: 1.0736\n",
      "Epoch 67/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0585 - val_loss: 1.0710\n",
      "Epoch 68/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0580 - val_loss: 1.0697\n",
      "Epoch 69/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0567 - val_loss: 1.0704\n",
      "Epoch 70/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0566 - val_loss: 1.0682\n",
      "Epoch 71/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0558 - val_loss: 1.0674\n",
      "Epoch 72/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0546 - val_loss: 1.0662\n",
      "Epoch 73/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0545 - val_loss: 1.0658\n",
      "Epoch 74/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0535 - val_loss: 1.0639\n",
      "Epoch 75/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0522 - val_loss: 1.0648\n",
      "Epoch 76/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0514 - val_loss: 1.0637\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0512 - val_loss: 1.0644\n",
      "Epoch 78/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0504 - val_loss: 1.0633\n",
      "Epoch 79/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0497 - val_loss: 1.0627\n",
      "Epoch 80/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0490 - val_loss: 1.0612\n",
      "Epoch 81/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0484 - val_loss: 1.0609\n",
      "Epoch 82/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0475 - val_loss: 1.0587\n",
      "Epoch 83/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0469 - val_loss: 1.0576\n",
      "Epoch 84/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0463 - val_loss: 1.0573\n",
      "Epoch 85/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0456 - val_loss: 1.0571\n",
      "Epoch 86/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0447 - val_loss: 1.0562\n",
      "Epoch 87/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0437 - val_loss: 1.0583\n",
      "Epoch 88/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0436 - val_loss: 1.0541\n",
      "Epoch 89/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0424 - val_loss: 1.0543\n",
      "Epoch 90/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0420 - val_loss: 1.0543\n",
      "Epoch 91/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0395 - val_loss: 1.0544\n",
      "Epoch 92/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0400 - val_loss: 1.0499\n",
      "Epoch 93/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0388 - val_loss: 1.0522\n",
      "Epoch 94/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0381 - val_loss: 1.0488\n",
      "Epoch 95/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0367 - val_loss: 1.0486\n",
      "Epoch 96/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0358 - val_loss: 1.0507\n",
      "Epoch 97/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0355 - val_loss: 1.0482\n",
      "Epoch 98/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0345 - val_loss: 1.0450\n",
      "Epoch 99/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0348 - val_loss: 1.0452\n",
      "Epoch 100/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0330 - val_loss: 1.0432\n",
      "Epoch 101/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0319 - val_loss: 1.0453\n",
      "Epoch 102/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0310 - val_loss: 1.0455\n",
      "Epoch 103/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0300 - val_loss: 1.0439\n",
      "Epoch 104/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0296 - val_loss: 1.0443\n",
      "Epoch 105/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0289 - val_loss: 1.0467\n",
      "Epoch 106/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0283 - val_loss: 1.0423\n",
      "Epoch 107/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0266 - val_loss: 1.0426\n",
      "Epoch 108/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0270 - val_loss: 1.0402\n",
      "Epoch 109/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0273 - val_loss: 1.0385\n",
      "Epoch 110/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0262 - val_loss: 1.0396\n",
      "Epoch 111/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0259 - val_loss: 1.0369\n",
      "Epoch 112/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0248 - val_loss: 1.0407\n",
      "Epoch 113/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0246 - val_loss: 1.0393\n",
      "Epoch 114/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0242 - val_loss: 1.0366\n",
      "Epoch 115/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0239 - val_loss: 1.0354\n",
      "Epoch 116/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0238 - val_loss: 1.0348\n",
      "Epoch 117/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0231 - val_loss: 1.0370\n",
      "Epoch 118/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0231 - val_loss: 1.0375\n",
      "Epoch 119/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0233 - val_loss: 1.0333\n",
      "Epoch 120/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0226 - val_loss: 1.0335\n",
      "Epoch 121/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0214 - val_loss: 1.0349\n",
      "Epoch 122/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0222 - val_loss: 1.0354\n",
      "Epoch 123/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0217 - val_loss: 1.0336\n",
      "Epoch 124/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0203 - val_loss: 1.0345\n",
      "Epoch 125/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0211 - val_loss: 1.0317\n",
      "Epoch 126/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0209 - val_loss: 1.0333\n",
      "Epoch 127/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0202 - val_loss: 1.0319\n",
      "Epoch 128/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0203 - val_loss: 1.0305\n",
      "Epoch 129/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0200 - val_loss: 1.0312\n",
      "Epoch 130/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0198 - val_loss: 1.0333\n",
      "Epoch 131/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0204 - val_loss: 1.0321\n",
      "Epoch 132/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0190 - val_loss: 1.0338\n",
      "Epoch 133/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0208 - val_loss: 1.0342\n",
      "Epoch 134/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0194 - val_loss: 1.0340\n",
      "Epoch 135/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0183 - val_loss: 1.0300\n",
      "Epoch 136/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0187 - val_loss: 1.0310\n",
      "Epoch 137/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0182 - val_loss: 1.0310\n",
      "Epoch 138/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0179 - val_loss: 1.0288\n",
      "Epoch 139/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0174 - val_loss: 1.0294\n",
      "Epoch 140/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0177 - val_loss: 1.0317\n",
      "Epoch 141/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0175 - val_loss: 1.0318\n",
      "Epoch 142/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0173 - val_loss: 1.0298\n",
      "Epoch 143/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0169 - val_loss: 1.0285\n",
      "Epoch 144/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0171 - val_loss: 1.0291\n",
      "Epoch 145/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0165 - val_loss: 1.0282\n",
      "Epoch 146/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0167 - val_loss: 1.0324\n",
      "Epoch 147/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0173 - val_loss: 1.0283\n",
      "Epoch 148/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0163 - val_loss: 1.0280\n",
      "Epoch 149/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0155 - val_loss: 1.0286\n",
      "Epoch 150/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0159 - val_loss: 1.0291\n",
      "Epoch 151/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0161 - val_loss: 1.0261\n",
      "Epoch 152/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0159 - val_loss: 1.0272\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0157 - val_loss: 1.0280\n",
      "Epoch 154/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0153 - val_loss: 1.0283\n",
      "Epoch 155/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0154 - val_loss: 1.0256\n",
      "Epoch 156/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0151 - val_loss: 1.0278\n",
      "Epoch 157/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0146 - val_loss: 1.0280\n",
      "Epoch 158/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0147 - val_loss: 1.0253\n",
      "Epoch 159/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0150 - val_loss: 1.0284\n",
      "Epoch 160/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0143 - val_loss: 1.0271\n",
      "Epoch 161/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0141 - val_loss: 1.0278\n",
      "Epoch 162/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0139 - val_loss: 1.0253\n",
      "Epoch 163/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0133 - val_loss: 1.0279\n",
      "Epoch 164/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0131 - val_loss: 1.0267\n",
      "Epoch 165/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0135 - val_loss: 1.0249\n",
      "Epoch 166/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0137 - val_loss: 1.0286\n",
      "Epoch 167/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0139 - val_loss: 1.0289\n",
      "Epoch 168/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0134 - val_loss: 1.0236\n",
      "Epoch 169/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0127 - val_loss: 1.0262\n",
      "Epoch 170/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0126 - val_loss: 1.0260\n",
      "Epoch 171/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0124 - val_loss: 1.0244\n",
      "Epoch 172/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0127 - val_loss: 1.0241\n",
      "Epoch 173/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0125 - val_loss: 1.0264\n",
      "Epoch 174/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0125 - val_loss: 1.0254\n",
      "Epoch 175/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0115 - val_loss: 1.0239\n",
      "Epoch 176/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0116 - val_loss: 1.0255\n",
      "Epoch 177/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0114 - val_loss: 1.0286\n",
      "Epoch 178/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0121 - val_loss: 1.0232\n",
      "Epoch 179/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0118 - val_loss: 1.0258\n",
      "Epoch 180/500\n",
      "40000/40000 [==============================] - ETA: 0s - loss: 1.011 - 1s 13us/step - loss: 1.0114 - val_loss: 1.0242\n",
      "Epoch 181/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0123 - val_loss: 1.0255\n",
      "Epoch 182/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0119 - val_loss: 1.0225\n",
      "Epoch 183/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0115 - val_loss: 1.0223\n",
      "Epoch 184/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0111 - val_loss: 1.0224\n",
      "Epoch 185/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0109 - val_loss: 1.0247\n",
      "Epoch 186/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0109 - val_loss: 1.0249\n",
      "Epoch 187/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0108 - val_loss: 1.0218\n",
      "Epoch 188/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0102 - val_loss: 1.0226\n",
      "Epoch 189/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0101 - val_loss: 1.0236\n",
      "Epoch 190/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.0104 - val_loss: 1.0200\n",
      "Epoch 191/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0103 - val_loss: 1.0235\n",
      "Epoch 192/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0107 - val_loss: 1.0227\n",
      "Epoch 193/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0101 - val_loss: 1.0237\n",
      "Epoch 194/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0100 - val_loss: 1.0202\n",
      "Epoch 195/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0095 - val_loss: 1.0221\n",
      "Epoch 196/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0104 - val_loss: 1.0232\n",
      "Epoch 197/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0094 - val_loss: 1.0204\n",
      "Epoch 198/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0090 - val_loss: 1.0201\n",
      "Epoch 199/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0092 - val_loss: 1.0267\n",
      "Epoch 200/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0091 - val_loss: 1.0187\n",
      "Epoch 201/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0086 - val_loss: 1.0233\n",
      "Epoch 202/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0090 - val_loss: 1.0229\n",
      "Epoch 203/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0085 - val_loss: 1.0203\n",
      "Epoch 204/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0091 - val_loss: 1.0207\n",
      "Epoch 205/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0082 - val_loss: 1.0183\n",
      "Epoch 206/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0085 - val_loss: 1.0201\n",
      "Epoch 207/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0091 - val_loss: 1.0199\n",
      "Epoch 208/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0085 - val_loss: 1.0215\n",
      "Epoch 209/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0086 - val_loss: 1.0190\n",
      "Epoch 210/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0084 - val_loss: 1.0201\n",
      "Epoch 211/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0084 - val_loss: 1.0221\n",
      "Epoch 212/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0086 - val_loss: 1.0178\n",
      "Epoch 213/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0083 - val_loss: 1.0221\n",
      "Epoch 214/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0086 - val_loss: 1.0212\n",
      "Epoch 215/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0085 - val_loss: 1.0200\n",
      "Epoch 216/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0079 - val_loss: 1.0228\n",
      "Epoch 217/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0079 - val_loss: 1.0196\n",
      "Epoch 218/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0073 - val_loss: 1.0212\n",
      "Epoch 219/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0078 - val_loss: 1.0190\n",
      "Epoch 220/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0073 - val_loss: 1.0216\n",
      "Epoch 221/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0074 - val_loss: 1.0203\n",
      "Epoch 222/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0075 - val_loss: 1.0177\n",
      "Epoch 223/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0075 - val_loss: 1.0192\n",
      "Epoch 224/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0072 - val_loss: 1.0195\n",
      "Epoch 225/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0075 - val_loss: 1.0217\n",
      "Epoch 226/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0079 - val_loss: 1.0187\n",
      "Epoch 227/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0074 - val_loss: 1.0219\n",
      "Epoch 228/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0070 - val_loss: 1.0173\n",
      "Epoch 229/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0072 - val_loss: 1.0168\n",
      "Epoch 230/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0072 - val_loss: 1.0211\n",
      "Epoch 231/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0075 - val_loss: 1.0180\n",
      "Epoch 232/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0063 - val_loss: 1.0205\n",
      "Epoch 233/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0074 - val_loss: 1.0192\n",
      "Epoch 234/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0066 - val_loss: 1.0180\n",
      "Epoch 235/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0066 - val_loss: 1.0189\n",
      "Epoch 236/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0066 - val_loss: 1.0213\n",
      "Epoch 237/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0068 - val_loss: 1.0207\n",
      "Epoch 238/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0068 - val_loss: 1.0190\n",
      "Epoch 239/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0063 - val_loss: 1.0186\n",
      "Epoch 240/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0066 - val_loss: 1.0182\n",
      "Epoch 241/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0061 - val_loss: 1.0182\n",
      "Epoch 242/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0066 - val_loss: 1.0169\n",
      "Epoch 243/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0059 - val_loss: 1.0205\n",
      "Epoch 244/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0059 - val_loss: 1.0169\n",
      "Epoch 245/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0058 - val_loss: 1.0195\n",
      "Epoch 246/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0063 - val_loss: 1.0189\n",
      "Epoch 247/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0059 - val_loss: 1.0164\n",
      "Epoch 248/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0060 - val_loss: 1.0186\n",
      "Epoch 249/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0061 - val_loss: 1.0171\n",
      "Epoch 250/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0063 - val_loss: 1.0202\n",
      "Epoch 251/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0059 - val_loss: 1.0196\n",
      "Epoch 252/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0057 - val_loss: 1.0200\n",
      "Epoch 253/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0061 - val_loss: 1.0154\n",
      "Epoch 254/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0058 - val_loss: 1.0187\n",
      "Epoch 255/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0061 - val_loss: 1.0154\n",
      "Epoch 256/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0062 - val_loss: 1.0183\n",
      "Epoch 257/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0057 - val_loss: 1.0169\n",
      "Epoch 258/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0053 - val_loss: 1.0182\n",
      "Epoch 259/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0060 - val_loss: 1.0177\n",
      "Epoch 260/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0060 - val_loss: 1.0178\n",
      "Epoch 261/500\n",
      "40000/40000 [==============================] - ETA: 0s - loss: 1.007 - 1s 13us/step - loss: 1.0060 - val_loss: 1.0184\n",
      "Epoch 262/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0053 - val_loss: 1.0182\n",
      "Epoch 263/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0053 - val_loss: 1.0183\n",
      "Epoch 264/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0052 - val_loss: 1.0174\n",
      "Epoch 265/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0058 - val_loss: 1.0184\n",
      "Epoch 266/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0053 - val_loss: 1.0224\n",
      "Epoch 267/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0051 - val_loss: 1.0218\n",
      "Epoch 268/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0052 - val_loss: 1.0174\n",
      "Epoch 269/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.0055 - val_loss: 1.0160\n",
      "Epoch 270/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0053 - val_loss: 1.0161\n",
      "Epoch 271/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0043 - val_loss: 1.0181\n",
      "Epoch 272/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0054 - val_loss: 1.0162\n",
      "Epoch 273/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0054 - val_loss: 1.0159\n",
      "Epoch 274/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0050 - val_loss: 1.0188\n",
      "Epoch 275/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0050 - val_loss: 1.0177\n",
      "Epoch 276/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0052 - val_loss: 1.0165\n",
      "Epoch 277/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0050 - val_loss: 1.0212\n",
      "Epoch 278/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0050 - val_loss: 1.0192\n",
      "Epoch 279/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0054 - val_loss: 1.0147\n",
      "Epoch 280/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0049 - val_loss: 1.0173\n",
      "Epoch 281/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0044 - val_loss: 1.0179\n",
      "Epoch 282/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0053 - val_loss: 1.0182\n",
      "Epoch 283/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0059 - val_loss: 1.0176\n",
      "Epoch 284/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0046 - val_loss: 1.0160\n",
      "Epoch 285/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0047 - val_loss: 1.0186\n",
      "Epoch 286/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0047 - val_loss: 1.0141\n",
      "Epoch 287/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0048 - val_loss: 1.0161\n",
      "Epoch 288/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0045 - val_loss: 1.0158\n",
      "Epoch 289/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0041 - val_loss: 1.0154\n",
      "Epoch 290/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0049 - val_loss: 1.0185\n",
      "Epoch 291/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0051 - val_loss: 1.0206\n",
      "Epoch 292/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0047 - val_loss: 1.0183\n",
      "Epoch 293/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0040 - val_loss: 1.0154\n",
      "Epoch 294/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0040 - val_loss: 1.0163\n",
      "Epoch 295/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0046 - val_loss: 1.0184\n",
      "Epoch 296/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0049 - val_loss: 1.0147\n",
      "Epoch 297/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0045 - val_loss: 1.0157\n",
      "Epoch 298/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0043 - val_loss: 1.0151\n",
      "Epoch 299/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0041 - val_loss: 1.0178\n",
      "Epoch 300/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0042 - val_loss: 1.0156\n",
      "Epoch 301/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0046 - val_loss: 1.0165\n",
      "Epoch 302/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0043 - val_loss: 1.0187\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0043 - val_loss: 1.0173\n",
      "Epoch 304/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0047 - val_loss: 1.0173\n",
      "Epoch 305/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0038 - val_loss: 1.0159\n",
      "Epoch 306/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0045 - val_loss: 1.0182\n",
      "Epoch 307/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0036 - val_loss: 1.0149\n",
      "Epoch 308/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0040 - val_loss: 1.0176\n",
      "Epoch 309/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0041 - val_loss: 1.0136\n",
      "Epoch 310/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0039 - val_loss: 1.0150\n",
      "Epoch 311/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0044 - val_loss: 1.0144\n",
      "Epoch 312/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0046 - val_loss: 1.0157\n",
      "Epoch 313/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0040 - val_loss: 1.0153\n",
      "Epoch 314/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0037 - val_loss: 1.0136\n",
      "Epoch 315/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0046 - val_loss: 1.0160\n",
      "Epoch 316/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0042 - val_loss: 1.0158\n",
      "Epoch 317/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0032 - val_loss: 1.0138\n",
      "Epoch 318/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0036 - val_loss: 1.0150- ETA: 0s - loss: 1.0\n",
      "Epoch 319/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0036 - val_loss: 1.0151\n",
      "Epoch 320/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0039 - val_loss: 1.0154\n",
      "Epoch 321/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0040 - val_loss: 1.0166\n",
      "Epoch 322/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0039 - val_loss: 1.0151\n",
      "Epoch 323/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0038 - val_loss: 1.0167\n",
      "Epoch 324/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0035 - val_loss: 1.0132\n",
      "Epoch 325/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0040 - val_loss: 1.0159\n",
      "Epoch 326/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0037 - val_loss: 1.0141\n",
      "Epoch 327/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0037 - val_loss: 1.0132\n",
      "Epoch 328/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0045 - val_loss: 1.0153\n",
      "Epoch 329/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0036 - val_loss: 1.0122\n",
      "Epoch 330/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0032 - val_loss: 1.0150\n",
      "Epoch 331/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0036 - val_loss: 1.0152\n",
      "Epoch 332/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0040 - val_loss: 1.0136\n",
      "Epoch 333/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0034 - val_loss: 1.0156\n",
      "Epoch 334/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0036 - val_loss: 1.0143\n",
      "Epoch 335/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0035 - val_loss: 1.0139\n",
      "Epoch 336/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0038 - val_loss: 1.0144\n",
      "Epoch 337/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0032 - val_loss: 1.0148\n",
      "Epoch 338/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0032 - val_loss: 1.0138\n",
      "Epoch 339/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0034 - val_loss: 1.0170\n",
      "Epoch 340/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0030 - val_loss: 1.0149\n",
      "Epoch 341/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0031 - val_loss: 1.0176\n",
      "Epoch 342/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0028 - val_loss: 1.0145\n",
      "Epoch 343/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0030 - val_loss: 1.0148\n",
      "Epoch 344/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0034 - val_loss: 1.0156\n",
      "Epoch 345/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0030 - val_loss: 1.0127\n",
      "Epoch 346/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0030 - val_loss: 1.0140\n",
      "Epoch 347/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0032 - val_loss: 1.0118\n",
      "Epoch 348/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0037 - val_loss: 1.0192\n",
      "Epoch 349/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0028 - val_loss: 1.0144\n",
      "Epoch 350/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0036 - val_loss: 1.0174\n",
      "Epoch 351/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0030 - val_loss: 1.0138\n",
      "Epoch 352/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0039 - val_loss: 1.0135\n",
      "Epoch 353/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0032 - val_loss: 1.0150\n",
      "Epoch 354/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0032 - val_loss: 1.0156\n",
      "Epoch 355/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0028 - val_loss: 1.0156\n",
      "Epoch 356/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0031 - val_loss: 1.0140\n",
      "Epoch 357/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0035 - val_loss: 1.0143\n",
      "Epoch 358/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0026 - val_loss: 1.0150\n",
      "Epoch 359/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0027 - val_loss: 1.0166\n",
      "Epoch 360/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0024 - val_loss: 1.0131\n",
      "Epoch 361/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0028 - val_loss: 1.0151\n",
      "Epoch 362/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0029 - val_loss: 1.0138\n",
      "Epoch 363/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0024 - val_loss: 1.0142\n",
      "Epoch 364/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0031 - val_loss: 1.0152\n",
      "Epoch 365/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0027 - val_loss: 1.0141\n",
      "Epoch 366/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0028 - val_loss: 1.0140\n",
      "Epoch 367/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0022 - val_loss: 1.0159\n",
      "Epoch 368/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0023 - val_loss: 1.0158\n",
      "Epoch 369/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0030 - val_loss: 1.0152\n",
      "Epoch 370/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0026 - val_loss: 1.0136\n",
      "Epoch 371/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0027 - val_loss: 1.0138\n",
      "Epoch 372/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0023 - val_loss: 1.0159\n",
      "Epoch 373/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0025 - val_loss: 1.0140\n",
      "Epoch 374/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0027 - val_loss: 1.0137\n",
      "Epoch 375/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0028 - val_loss: 1.0115\n",
      "Epoch 376/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0023 - val_loss: 1.0132\n",
      "Epoch 377/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0030 - val_loss: 1.0147\n",
      "Epoch 378/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0022 - val_loss: 1.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0022 - val_loss: 1.0151\n",
      "Epoch 380/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0020 - val_loss: 1.0131\n",
      "Epoch 381/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0029 - val_loss: 1.0136\n",
      "Epoch 382/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0021 - val_loss: 1.0130\n",
      "Epoch 383/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0024 - val_loss: 1.0145\n",
      "Epoch 384/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0023 - val_loss: 1.0120\n",
      "Epoch 385/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0023 - val_loss: 1.0124\n",
      "Epoch 386/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0026 - val_loss: 1.0149\n",
      "Epoch 387/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0016 - val_loss: 1.0134\n",
      "Epoch 388/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0027 - val_loss: 1.0137\n",
      "Epoch 389/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0023 - val_loss: 1.0137\n",
      "Epoch 390/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0020 - val_loss: 1.0153\n",
      "Epoch 391/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0028 - val_loss: 1.0121\n",
      "Epoch 392/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0023 - val_loss: 1.0147\n",
      "Epoch 393/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.0016 - val_loss: 1.0117\n",
      "Epoch 394/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.0019 - val_loss: 1.0129\n",
      "Epoch 395/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0019 - val_loss: 1.0135\n",
      "Epoch 396/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0025 - val_loss: 1.0116\n",
      "Epoch 397/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0025 - val_loss: 1.0157\n",
      "Epoch 398/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0025 - val_loss: 1.0163\n",
      "Epoch 399/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0020 - val_loss: 1.0134\n",
      "Epoch 400/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0017 - val_loss: 1.0118\n",
      "Epoch 401/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0014 - val_loss: 1.0145\n",
      "Epoch 402/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0025 - val_loss: 1.0186\n",
      "Epoch 403/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0025 - val_loss: 1.0118\n",
      "Epoch 404/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0015 - val_loss: 1.0121\n",
      "Epoch 405/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0016 - val_loss: 1.0108\n",
      "Epoch 406/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0013 - val_loss: 1.0155\n",
      "Epoch 407/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0011 - val_loss: 1.0139\n",
      "Epoch 408/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0019 - val_loss: 1.0126\n",
      "Epoch 409/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0014 - val_loss: 1.0109\n",
      "Epoch 410/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0019 - val_loss: 1.0125\n",
      "Epoch 411/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0019 - val_loss: 1.0180\n",
      "Epoch 412/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0017 - val_loss: 1.0140\n",
      "Epoch 413/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0018 - val_loss: 1.0118\n",
      "Epoch 414/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0018 - val_loss: 1.0151\n",
      "Epoch 415/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0017 - val_loss: 1.0123\n",
      "Epoch 416/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0011 - val_loss: 1.0103\n",
      "Epoch 417/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0012 - val_loss: 1.0134\n",
      "Epoch 418/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0018 - val_loss: 1.0100\n",
      "Epoch 419/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0015 - val_loss: 1.0127\n",
      "Epoch 420/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0017 - val_loss: 1.0100\n",
      "Epoch 421/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0013 - val_loss: 1.0110\n",
      "Epoch 422/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0015 - val_loss: 1.0143\n",
      "Epoch 423/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.0012 - val_loss: 1.0152\n",
      "Epoch 424/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0014 - val_loss: 1.0110\n",
      "Epoch 425/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0006 - val_loss: 1.0098\n",
      "Epoch 426/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0011 - val_loss: 1.0129\n",
      "Epoch 427/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0014 - val_loss: 1.0126\n",
      "Epoch 428/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0010 - val_loss: 1.0149\n",
      "Epoch 429/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0012 - val_loss: 1.0109\n",
      "Epoch 430/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0014 - val_loss: 1.0107\n",
      "Epoch 431/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0012 - val_loss: 1.0122\n",
      "Epoch 432/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0010 - val_loss: 1.0141\n",
      "Epoch 433/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 1.0008 - val_loss: 1.0114\n",
      "Epoch 434/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0009 - val_loss: 1.0116\n",
      "Epoch 435/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0009 - val_loss: 1.0128\n",
      "Epoch 436/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0009 - val_loss: 1.0120\n",
      "Epoch 437/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0005 - val_loss: 1.0129\n",
      "Epoch 438/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 1.0015 - val_loss: 1.0124\n",
      "Epoch 439/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 1.0012 - val_loss: 1.0108\n",
      "Epoch 440/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0007 - val_loss: 1.0148\n",
      "Epoch 441/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0009 - val_loss: 1.0104\n",
      "Epoch 442/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0006 - val_loss: 1.0125\n",
      "Epoch 443/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0003 - val_loss: 1.0107\n",
      "Epoch 444/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 1.0008 - val_loss: 1.0115\n",
      "Epoch 445/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0004 - val_loss: 1.0121\n",
      "Epoch 446/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0007 - val_loss: 1.0139\n",
      "Epoch 447/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0008 - val_loss: 1.0135\n",
      "Epoch 448/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0008 - val_loss: 1.0098\n",
      "Epoch 449/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0001 - val_loss: 1.0110\n",
      "Epoch 450/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0005 - val_loss: 1.0137\n",
      "Epoch 451/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0004 - val_loss: 1.0094\n",
      "Epoch 452/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0006 - val_loss: 1.0086\n",
      "Epoch 453/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0011 - val_loss: 1.0096\n",
      "Epoch 454/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9998 - val_loss: 1.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0003 - val_loss: 1.0094\n",
      "Epoch 456/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0001 - val_loss: 1.0092\n",
      "Epoch 457/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0002 - val_loss: 1.0120\n",
      "Epoch 458/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0002 - val_loss: 1.0120\n",
      "Epoch 459/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.9999 - val_loss: 1.0091\n",
      "Epoch 460/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9996 - val_loss: 1.0133\n",
      "Epoch 461/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0004 - val_loss: 1.0123\n",
      "Epoch 462/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9997 - val_loss: 1.0136\n",
      "Epoch 463/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0001 - val_loss: 1.0123\n",
      "Epoch 464/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9994 - val_loss: 1.0109\n",
      "Epoch 465/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9999 - val_loss: 1.0110\n",
      "Epoch 466/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 1.0003 - val_loss: 1.0093\n",
      "Epoch 467/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0001 - val_loss: 1.0168\n",
      "Epoch 468/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9994 - val_loss: 1.0112\n",
      "Epoch 469/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0002 - val_loss: 1.0078\n",
      "Epoch 470/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0002 - val_loss: 1.0093\n",
      "Epoch 471/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9991 - val_loss: 1.0126\n",
      "Epoch 472/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9991 - val_loss: 1.0118\n",
      "Epoch 473/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9999 - val_loss: 1.0137\n",
      "Epoch 474/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9997 - val_loss: 1.0097\n",
      "Epoch 475/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9996 - val_loss: 1.0105\n",
      "Epoch 476/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9993 - val_loss: 1.0127\n",
      "Epoch 477/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9991 - val_loss: 1.0110\n",
      "Epoch 478/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.9991 - val_loss: 1.0119\n",
      "Epoch 479/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9995 - val_loss: 1.0092\n",
      "Epoch 480/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9990 - val_loss: 1.0099\n",
      "Epoch 481/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9990 - val_loss: 1.0099\n",
      "Epoch 482/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9986 - val_loss: 1.0108\n",
      "Epoch 483/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9990 - val_loss: 1.0108\n",
      "Epoch 484/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9992 - val_loss: 1.0120\n",
      "Epoch 485/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9991 - val_loss: 1.0109\n",
      "Epoch 486/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9992 - val_loss: 1.0100\n",
      "Epoch 487/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9989 - val_loss: 1.0115\n",
      "Epoch 488/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9993 - val_loss: 1.0087\n",
      "Epoch 489/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9989 - val_loss: 1.0110\n",
      "Epoch 490/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 1.0001 - val_loss: 1.0135\n",
      "Epoch 491/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9997 - val_loss: 1.0089\n",
      "Epoch 492/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9993 - val_loss: 1.0088\n",
      "Epoch 493/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9990 - val_loss: 1.0110\n",
      "Epoch 494/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9997 - val_loss: 1.0128\n",
      "Epoch 495/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9992 - val_loss: 1.0107\n",
      "Epoch 496/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9993 - val_loss: 1.0120\n",
      "Epoch 497/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9991 - val_loss: 1.0099\n",
      "Epoch 498/500\n",
      "40000/40000 [==============================] - 0s 11us/step - loss: 0.9991 - val_loss: 1.0108\n",
      "Epoch 499/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9983 - val_loss: 1.0110\n",
      "Epoch 500/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.9982 - val_loss: 1.0081\n"
     ]
    }
   ],
   "source": [
    "autoencoder_train1=vae1.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n",
    "vae1.save_weights('vae_explicit_even_circular1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = autoencoder_train1.history['loss']\n",
    "val_loss = autoencoder_train1.history['val_loss']\n",
    "epochs_plot = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs_plot, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs_plot, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test1 = vae1.predict(x_test)\n",
    "pred_train1 = vae1.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10001 samples\n",
      "Epoch 1/500\n",
      "40000/40000 [==============================] - 1s 18us/step - loss: 1.2570 - val_loss: 0.9216\n",
      "Epoch 2/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.8851 - val_loss: 0.8769\n",
      "Epoch 3/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.8525 - val_loss: 0.8568\n",
      "Epoch 4/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.8374 - val_loss: 0.8431\n",
      "Epoch 5/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.8265 - val_loss: 0.8322\n",
      "Epoch 6/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.8155 - val_loss: 0.8216\n",
      "Epoch 7/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.8049 - val_loss: 0.8140\n",
      "Epoch 8/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.7950 - val_loss: 0.8075\n",
      "Epoch 9/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.7860 - val_loss: 0.7928\n",
      "Epoch 10/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.7674 - val_loss: 0.7541\n",
      "Epoch 11/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.7191 - val_loss: 0.7205\n",
      "Epoch 12/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.7028 - val_loss: 0.7104\n",
      "Epoch 13/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.6982 - val_loss: 0.7047\n",
      "Epoch 14/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.6952 - val_loss: 0.7022\n",
      "Epoch 15/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.6938 - val_loss: 0.6998\n",
      "Epoch 16/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.6919 - val_loss: 0.6989\n",
      "Epoch 17/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.6898 - val_loss: 0.6972\n",
      "Epoch 18/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.6889 - val_loss: 0.6957\n",
      "Epoch 19/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.6859 - val_loss: 0.6903\n",
      "Epoch 20/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.6838 - val_loss: 0.6901\n",
      "Epoch 21/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.6808 - val_loss: 0.6845\n",
      "Epoch 22/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.6771 - val_loss: 0.6820\n",
      "Epoch 23/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.6732 - val_loss: 0.6765\n",
      "Epoch 24/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.6688 - val_loss: 0.6721\n",
      "Epoch 25/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.6633 - val_loss: 0.6661\n",
      "Epoch 26/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.6575 - val_loss: 0.6561\n",
      "Epoch 27/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.6478 - val_loss: 0.6429\n",
      "Epoch 28/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.6260 - val_loss: 0.6156\n",
      "Epoch 29/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.6003 - val_loss: 0.5977\n",
      "Epoch 30/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5901 - val_loss: 0.5902\n",
      "Epoch 31/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5851 - val_loss: 0.5876\n",
      "Epoch 32/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5803 - val_loss: 0.5829\n",
      "Epoch 33/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5754 - val_loss: 0.5785\n",
      "Epoch 34/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5712 - val_loss: 0.5746\n",
      "Epoch 35/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5673 - val_loss: 0.5728\n",
      "Epoch 36/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5638 - val_loss: 0.5695\n",
      "Epoch 37/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5618 - val_loss: 0.5668\n",
      "Epoch 38/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5580 - val_loss: 0.5657\n",
      "Epoch 39/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5563 - val_loss: 0.5613\n",
      "Epoch 40/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5544 - val_loss: 0.5634\n",
      "Epoch 41/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5527 - val_loss: 0.5576\n",
      "Epoch 42/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5504 - val_loss: 0.5569\n",
      "Epoch 43/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5497 - val_loss: 0.5572\n",
      "Epoch 44/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5475 - val_loss: 0.5556\n",
      "Epoch 45/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5459 - val_loss: 0.5562\n",
      "Epoch 46/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5447 - val_loss: 0.5551\n",
      "Epoch 47/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5430 - val_loss: 0.5539\n",
      "Epoch 48/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5428 - val_loss: 0.5488\n",
      "Epoch 49/500\n",
      "40000/40000 [==============================] - 1s 18us/step - loss: 0.5413 - val_loss: 0.5500\n",
      "Epoch 50/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5406 - val_loss: 0.5484\n",
      "Epoch 51/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5390 - val_loss: 0.5469\n",
      "Epoch 52/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5390 - val_loss: 0.5472\n",
      "Epoch 53/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5378 - val_loss: 0.5475\n",
      "Epoch 54/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5368 - val_loss: 0.5460\n",
      "Epoch 55/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5364 - val_loss: 0.5457\n",
      "Epoch 56/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5354 - val_loss: 0.5458\n",
      "Epoch 57/500\n",
      "40000/40000 [==============================] - 1s 20us/step - loss: 0.5352 - val_loss: 0.5425\n",
      "Epoch 58/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5346 - val_loss: 0.5422\n",
      "Epoch 59/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5332 - val_loss: 0.5412\n",
      "Epoch 60/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5330 - val_loss: 0.5414\n",
      "Epoch 61/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5331 - val_loss: 0.5415\n",
      "Epoch 62/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5319 - val_loss: 0.5393\n",
      "Epoch 63/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5308 - val_loss: 0.5371\n",
      "Epoch 64/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5302 - val_loss: 0.5386\n",
      "Epoch 65/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5302 - val_loss: 0.5384\n",
      "Epoch 66/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5290 - val_loss: 0.5386\n",
      "Epoch 67/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5306 - val_loss: 0.5362\n",
      "Epoch 68/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5284 - val_loss: 0.5378\n",
      "Epoch 69/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5279 - val_loss: 0.5356\n",
      "Epoch 70/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5278 - val_loss: 0.5348\n",
      "Epoch 71/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5286 - val_loss: 0.5366\n",
      "Epoch 72/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5271 - val_loss: 0.5361\n",
      "Epoch 73/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5266 - val_loss: 0.5340\n",
      "Epoch 74/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5258 - val_loss: 0.5325\n",
      "Epoch 75/500\n",
      "40000/40000 [==============================] - 1s 18us/step - loss: 0.5255 - val_loss: 0.5333\n",
      "Epoch 76/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5248 - val_loss: 0.5353\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 19us/step - loss: 0.5248 - val_loss: 0.5345\n",
      "Epoch 78/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5243 - val_loss: 0.5350\n",
      "Epoch 79/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5238 - val_loss: 0.5312\n",
      "Epoch 80/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5241 - val_loss: 0.5343\n",
      "Epoch 81/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5239 - val_loss: 0.5338\n",
      "Epoch 82/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5235 - val_loss: 0.5311\n",
      "Epoch 83/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5233 - val_loss: 0.5315\n",
      "Epoch 84/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5227 - val_loss: 0.5315\n",
      "Epoch 85/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5226 - val_loss: 0.5295\n",
      "Epoch 86/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5237 - val_loss: 0.5315\n",
      "Epoch 87/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5225 - val_loss: 0.5304\n",
      "Epoch 88/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5217 - val_loss: 0.5298\n",
      "Epoch 89/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.5213 - val_loss: 0.5324\n",
      "Epoch 90/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5208 - val_loss: 0.5301\n",
      "Epoch 91/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5201 - val_loss: 0.5282\n",
      "Epoch 92/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5214 - val_loss: 0.5280\n",
      "Epoch 93/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5199 - val_loss: 0.5316\n",
      "Epoch 94/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5205 - val_loss: 0.5274\n",
      "Epoch 95/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5195 - val_loss: 0.5266\n",
      "Epoch 96/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.5191 - val_loss: 0.5271\n",
      "Epoch 97/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5196 - val_loss: 0.5269\n",
      "Epoch 98/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5193 - val_loss: 0.5291\n",
      "Epoch 99/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5193 - val_loss: 0.5269\n",
      "Epoch 100/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.5183 - val_loss: 0.5250\n",
      "Epoch 101/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5178 - val_loss: 0.5260\n",
      "Epoch 102/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5180 - val_loss: 0.5250\n",
      "Epoch 103/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5184 - val_loss: 0.5276\n",
      "Epoch 104/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5173 - val_loss: 0.5229\n",
      "Epoch 105/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5170 - val_loss: 0.5252\n",
      "Epoch 106/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5171 - val_loss: 0.5253\n",
      "Epoch 107/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5165 - val_loss: 0.5238\n",
      "Epoch 108/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5156 - val_loss: 0.5253\n",
      "Epoch 109/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5154 - val_loss: 0.5276\n",
      "Epoch 110/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.5155 - val_loss: 0.5266\n",
      "Epoch 111/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5157 - val_loss: 0.5219\n",
      "Epoch 112/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5163 - val_loss: 0.5222\n",
      "Epoch 113/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.5146 - val_loss: 0.5295\n",
      "Epoch 114/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5151 - val_loss: 0.5213\n",
      "Epoch 115/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5140 - val_loss: 0.5219\n",
      "Epoch 116/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5140 - val_loss: 0.5204\n",
      "Epoch 117/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5141 - val_loss: 0.5219\n",
      "Epoch 118/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5136 - val_loss: 0.5222\n",
      "Epoch 119/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5136 - val_loss: 0.5219\n",
      "Epoch 120/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5134 - val_loss: 0.5227\n",
      "Epoch 121/500\n",
      "40000/40000 [==============================] - 0s 12us/step - loss: 0.5134 - val_loss: 0.5189\n",
      "Epoch 122/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5130 - val_loss: 0.5200\n",
      "Epoch 123/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5120 - val_loss: 0.5195\n",
      "Epoch 124/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5136 - val_loss: 0.5195\n",
      "Epoch 125/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5132 - val_loss: 0.5190\n",
      "Epoch 126/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5128 - val_loss: 0.5185\n",
      "Epoch 127/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5127 - val_loss: 0.5214\n",
      "Epoch 128/500\n",
      "40000/40000 [==============================] - 1s 18us/step - loss: 0.5119 - val_loss: 0.5185\n",
      "Epoch 129/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5115 - val_loss: 0.5197\n",
      "Epoch 130/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5108 - val_loss: 0.5226\n",
      "Epoch 131/500\n",
      "40000/40000 [==============================] - 1s 18us/step - loss: 0.5110 - val_loss: 0.5225\n",
      "Epoch 132/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5109 - val_loss: 0.5196\n",
      "Epoch 133/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5118 - val_loss: 0.5204\n",
      "Epoch 134/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5105 - val_loss: 0.5174\n",
      "Epoch 135/500\n",
      "40000/40000 [==============================] - 1s 20us/step - loss: 0.5106 - val_loss: 0.5165\n",
      "Epoch 136/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5111 - val_loss: 0.5202\n",
      "Epoch 137/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5108 - val_loss: 0.5177\n",
      "Epoch 138/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5104 - val_loss: 0.5152\n",
      "Epoch 139/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5101 - val_loss: 0.5191\n",
      "Epoch 140/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5096 - val_loss: 0.5210\n",
      "Epoch 141/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5096 - val_loss: 0.5167\n",
      "Epoch 142/500\n",
      "40000/40000 [==============================] - 1s 14us/step - loss: 0.5099 - val_loss: 0.5182\n",
      "Epoch 143/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5091 - val_loss: 0.5177\n",
      "Epoch 144/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5093 - val_loss: 0.5169\n",
      "Epoch 145/500\n",
      "40000/40000 [==============================] - 1s 18us/step - loss: 0.5090 - val_loss: 0.5161\n",
      "Epoch 146/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5099 - val_loss: 0.5138\n",
      "Epoch 147/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5092 - val_loss: 0.5148\n",
      "Epoch 148/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5086 - val_loss: 0.5154\n",
      "Epoch 149/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5089 - val_loss: 0.5160\n",
      "Epoch 150/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5095 - val_loss: 0.5157\n",
      "Epoch 151/500\n",
      "40000/40000 [==============================] - 1s 15us/step - loss: 0.5090 - val_loss: 0.5143\n",
      "Epoch 152/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5091 - val_loss: 0.5139\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5089 - val_loss: 0.5124\n",
      "Epoch 154/500\n",
      "40000/40000 [==============================] - 1s 17us/step - loss: 0.5093 - val_loss: 0.5144\n",
      "Epoch 155/500\n",
      "40000/40000 [==============================] - 1s 16us/step - loss: 0.5083 - val_loss: 0.5160\n",
      "Epoch 156/500\n",
      "40000/40000 [==============================] - 1s 13us/step - loss: 0.5081 - val_loss: 0.5195\n",
      "Epoch 157/500\n",
      "31900/40000 [======================>.......] - ETA: 0s - loss: 0.5080"
     ]
    }
   ],
   "source": [
    "autoencoder_train2=vae2.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n",
    "vae2.save_weights('vae_explicit_even_circular2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train2.history['loss']\n",
    "val_loss = autoencoder_train2.history['val_loss']\n",
    "epochs_plot = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs_plot, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs_plot, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train3=vae3.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n",
    "vae3.save_weights('vae_explicit_even_circular3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train3.history['loss']\n",
    "val_loss = autoencoder_train3.history['val_loss']\n",
    "epochs_plot = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs_plot, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs_plot, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train4=vae4.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n",
    "vae4.save_weights('vae_explicit_even_circular4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train4.history['loss']\n",
    "val_loss = autoencoder_train4.history['val_loss']\n",
    "epochs_plot = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs_plot, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs_plot, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_train5=vae5.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n",
    "vae5.save_weights('vae_explicit_even_circular5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train5.history['loss']\n",
    "val_loss = autoencoder_train5.history['val_loss']\n",
    "epochs_plot = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs_plot, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs_plot, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test1 = encoder1.predict(x_test, batch_size=batch_size)\n",
    "decoder_test1=decoder1.predict(z_test1,batch_size=batch_size)\n",
    "\n",
    "z_test2 = encoder2.predict(x_test, batch_size=batch_size)\n",
    "decoder_test2=decoder2.predict(z_test2,batch_size=batch_size)\n",
    "\n",
    "z_test3 = encoder3.predict(x_test, batch_size=batch_size)\n",
    "decoder_test3=decoder3.predict(z_test3,batch_size=batch_size)\n",
    "\n",
    "z_test4 = encoder4.predict(x_test, batch_size=batch_size)\n",
    "decoder_test4=decoder4.predict(z_test4,batch_size=batch_size)\n",
    "\n",
    "z_test5 = encoder5.predict(x_test, batch_size=batch_size)\n",
    "decoder_test5=decoder5.predict(z_test5,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve1 = r2_score(x_test,decoder_test1)\n",
    "fve2 = r2_score(x_test,decoder_test2)\n",
    "fve3 = r2_score(x_test,decoder_test3)\n",
    "fve4 = r2_score(x_test,decoder_test4)\n",
    "fve5 = r2_score(x_test,decoder_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_scores = np.array([fve1,fve2,fve3,fve4,fve5])\n",
    "x=np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fve_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x,fve_scores,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
